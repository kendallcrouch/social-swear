{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules\n",
    "- ttools has helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, codecs, json\n",
    "import ttools\n",
    "from twython import TwythonStreamer, Twython\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top100 [from pre-made json file]\n",
    "First, load the dictionary with the top100 most followed twtter users and extract the user_ids for use in api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100file = './top100_id_dictionary.json'\n",
    "top100 = ttools.json_to_dict(top100file)  # format is {user_id:[username,name]} really we just care about the user ids for now\n",
    "top100ids = [int(uid) for uid in top100.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and inspect the top100 tweet/timeline data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 s, sys: 107 ms, total: 1.15 s\n",
      "Wall time: 1.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (0,2,5,6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "%time top100all = pd.read_csv('top100users_and_timelines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 203263 entries, 0 to 203262\n",
      "Data columns (total 18 columns):\n",
      "tweet_id                 203263 non-null object\n",
      "date                     203262 non-null object\n",
      "user_id                  203262 non-null object\n",
      "text                     203262 non-null object\n",
      "text_noMentions          203215 non-null object\n",
      "is_quote_status          203256 non-null object\n",
      "is_reply_to_status       203256 non-null object\n",
      "is_reply_to_user         203256 non-null object\n",
      "numMentions              203256 non-null float64\n",
      "user_verified            203256 non-null object\n",
      "user_description_text    161567 non-null object\n",
      "user_followers_count     203256 non-null float64\n",
      "user_friends_count       203256 non-null float64\n",
      "user_listed_count        203256 non-null float64\n",
      "user_favourites_count    203256 non-null float64\n",
      "user_statuses_count      203250 non-null float64\n",
      "retweet_count            203250 non-null float64\n",
      "favorite_count           203250 non-null float64\n",
      "dtypes: float64(8), object(10)\n",
      "memory usage: 27.9+ MB\n"
     ]
    }
   ],
   "source": [
    "top100all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to categorize the top100. Here is some helper code. The 'top100cat' dataframe is the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top100 category count:\n",
      "artist            60\n",
      "company           14\n",
      "athlete            9\n",
      "politician         7\n",
      "businessLeader     2\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#turn dict into dataframe\n",
    "top100forCategories = []\n",
    "for uid in list(top100.keys()):\n",
    "    top100forCategories.append([int(uid),top100[uid][0],top100[uid][1]])\n",
    "\n",
    "#save the dataframe\n",
    "pd.DataFrame(top100forCategories).to_csv('top100categorization.csv')\n",
    "#then, manually labeled each entry as one of the five categories. Saved labeled file as 'top100categorization_complete.csv'\n",
    "\n",
    "#Now, read in the complete csv. This df can be used with the 'top100users_and_timelines.csv' dataset to help\n",
    "#categorize the top100 users/tweets into correct category\n",
    "CATEGORY = {'a':'artist','b':'businessLeader','c':'company','p':'politician','t':'athlete'}\n",
    "top100cat = pd.read_csv('top100categorization_complete.csv')\n",
    "top100cat.drop(['Unnamed: 0','notes'],axis=1,inplace=True)\n",
    "top100cat.rename(columns={'0':'user_id','1':'screenname','2':'name'},inplace=True)\n",
    "print('top100 category count:\\n%s'%(top100cat['category'].value_counts().rename(CATEGORY)))\n",
    "#top100cat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example use: get ALL tweets from the top 100 users that came from all users labeled as athletes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_ids = set(top100cat[top100cat['category']=='t']['user_id'])\n",
    "#note...top100cat may include non-english id's. these are filtered out in top100all, so the set of user_id's that we catch in the next line\n",
    "#may be a subset of the set of user_ids within the category being filtered. i.e. there are 9 athletes in the top100, but one of their accounts\n",
    "#was non-english. So when we filter on atheletes, our tweet/timeline data will only have timelines for 8 athletes. this is not a problem,\n",
    "#just something to be aware of.\n",
    "athlete_tweets = top100all[top100all.apply(lambda x:x['user_id'] in athlete_ids,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17956 tweets [8.8%] of top100 dataset are from atheletes\n",
      "the athletes in the dataset are:\n",
      "45                     kaka\n",
      "48             fc barcelona\n",
      "55                      nba\n",
      "56         sachin tendulkar\n",
      "59              virat kohli\n",
      "68                      nfl\n",
      "73           andr√©s iniesta\n",
      "80    uefa champions league\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('%s tweets [%0.1f%%] of top100 dataset are from atheletes'%(athlete_tweets.shape[0],(athlete_tweets.shape[0]/top100all.shape[0])*100))\n",
    "print('the athletes in the dataset are:\\n%s'%(top100cat[top100cat.apply(lambda x:x['user_id'] in athlete_tweets['user_id'].unique(),axis=1)]['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
